---
title: "Exercise 6 - Nonlinear Models and Tree-based Methods"
output: html_document
---

### Exercise 6.1

This question relates to the `College` dataset from the `ISLR` package.

```{r, }
library(ISLR)
library(glmnet)
library(leaps)
```

(a) Split the data into a training set and a test set. Using out-of-state tuition as the response and the other variables as the predictors, perform appropriate model selection of your choice (from day6) on the training set in order to identify a satisfactory model that uses just a subset of the predictors.

```{r}
set.seed(11)
```

(b) Fit a GAM on the training data, using out-of-state tuition as the response and the features selected in the previous step as the predictors. Plot the results, and explain your findings.

```{r}
library(gam)
# non parametric regression - 
gam.fit <-  gam
```

(c) Evaluate the model obtained on the test set, and explain the results obtained.

```{r}
# gam.pred <- predict()  # uncomment and modify appropriately
```

(d) For which variables, if any, is there evidence of a non-linear relationship with the response?

```{r}
# summary(gam.fit)
```


### Exercise 6.2 

Apply bagging and random forests to a data set of your choice. Be sure to fit the models on a training set and to evaluate their performance on a test set. How accurate are the results compared to simple methods like linear or logistic regression? Which of these approaches yields the best performance?

**In this exercise we examine the `Weekly` stock market data from the ISLR package.**
```{r}
set.seed(1)
summary(Weekly)
# train <-  
# test <-
```

**Logistic regression**
```{r}

```

**Bagging**
```{r}

```

**Random forests**
```{r}
# rf.weekly <-  randomForest()
```

